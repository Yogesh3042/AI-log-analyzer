Great â€” here is a **professional, polished README.md** for your project.

You can copy-paste this entire content into your `readme.md` file in the root of your repo.

---

# ğŸ“˜ **AI Log Analyzer**

AI Log Analyzer is a lightweight, fast, developer-friendly tool that analyzes system/application logs using **local AI models (via Ollama)**.
It reads log files, detects issues, summarizes patterns, and provides actionable insights â€” all without sending any data outside your machine.

This project includes:

âœ… Go backend for log ingestion
âœ… Ollama AI integration (local LLMâ€”no API key needed)
âœ… Simple HTML/JS UI dashboard
âœ… Sample log files
âœ… Clean modular project structure

---

## ğŸš€ Features

### ğŸ” **AI-Powered Log Analysis**

* Detects anomalies, failures, spikes, latency issues.
* Summarizes logs into human-friendly insights.
* Generates recommendations for fixes.

### ğŸ–¥ï¸ **Web Dashboard**

* Upload logs
* Run â€œAI Analyzeâ€ with one click
* Get structured summary instantly

### âš¡ **Fast & Local**

* Runs entirely with **Ollama** (no external API, no billing).
* Works in Codespaces, Windows (no admin needed via Codespaces), Linux, macOS.

---

## ğŸ“‚ **Project Structure**

```
AI-log-analyzer/
â”‚
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                 # Entry point for HTTP server
â”‚
â”œâ”€â”€ internal/
â”‚   â””â”€â”€ analyzer/
â”‚       â”œâ”€â”€ analyzer.go         # Log reading + AI call
â”‚       â””â”€â”€ ollama_client.go    # Ollama API wrapper
â”‚
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ file_reader.go      # File reading helpers
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html              # UI Dashboard
â”‚   â”œâ”€â”€ app.js                  # Frontend logic
â”‚   â””â”€â”€ styles.css              # UI Styling
â”‚
â”œâ”€â”€ sample_logs/
â”‚   â””â”€â”€ sample.log              # Test logs
â”‚
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ **Tech Stack**

### **Backend**

* Go 1.22+
* Ollama (local AI)
* net/http

### **Frontend**

* HTML5
* Vanilla JS
* Fetch API
* Minimal CSS

---

## â–¶ï¸ **Running Locally**

### **1ï¸âƒ£ Install Ollama**

(Already pre-installed in GitHub Codespaces)

Otherwise:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Run the server:

```bash
ollama serve
```

### **2ï¸âƒ£ Pull a model**

Recommended:

```bash
ollama pull llama3.1
```

Check installed models:

```bash
ollama list
```

### **3ï¸âƒ£ Run the Go server**

From project root:

```bash
go run cmd/main.go
```

You should see:

```
ğŸŸ¢ AI Log Analyzer Started
```

### **4ï¸âƒ£ Open the UI**

If running locally:

```
http://localhost:8080
```

If using GitHub Codespaces â†’ click "Open in Browser".

---

## ğŸ“¤ **Usage**

### **Upload logs â†’ Analyze â†’ Get AI Summary**

The output includes:

* Total log lines
* Summary of events
* Key issues
* Recommendations

---

## ğŸ§ª Sample Output

```
Total log lines: 10

AI Summary:
- High API latency detected
- Redis timeout issues
- Payment gateway failure (502)
- High disk usage alert
```

---


## ğŸ¤ Contributing

Pull Requests are welcome!

---

## ğŸ“ License

This project is licensed under **MIT License**.

---

## â­ Support

If you like this project, star the repo â­ â€” it helps grow visibility & motivates more improvements.

---

